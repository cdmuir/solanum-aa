---
title: "Notes"
format: html
editor: visual
execute:
  enabled: true
---

Making some notes on methods that might be useful for writing later

## 2024-02-25

Actually, I did this profiling wrong, but I'm going to try model without autocorrelation anyway to compare.

I profiled the `solanum-aa` code and found that most (90.6%) of the time is spent on the `multi_normal` calculations. 

Next, I profiled the same model, ignoring residual autocorrelation. The speed-up is substantial (80\%). The time in this model is pretty evenly divided among various calculations and likelihood.

Note that total runtime was 5871.4 seconds for 400 iterations

| name         | total_time |
|--------------|------------|
| CO2_r likelihood | 297.691 |
| CO2_s likelihood | 238.332 |
| H2O_r likelihood | 304.786 |
| H2O_s likelihood | 306.439 |
| LICOR calcs | 1047.940 |
| priors | 749.983 |  
| regression | 645.282 |

Given the efficiency of model without residual autocorrelatiln, I will try fitting actual data with uncorrelated residuals first. If the residuals are highly correlated, then I will try a combination of thinning or accounting for autocorrelation, perhaps finding a more efficient approach.

## 2024-02-27

Current model (no autocorrelation) is taking less than two hours to run on HTC, with average of 10 points per curve. 40 total curves.

Current model (no autocorrelation) took ~8.33 hours to run LA2172 data on HTC, with average of 29 points per curve. 80 total curves.

Actual data usage was 2,669,308 KB (33,554,432 requested)
Actual memory usage was 2,580 MB (65,536 requested)
